<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>声の感情 → 花ジェネレーター</title>
  <style>
    :root{
      --bg:#0e1a3a; --ink:#f7f8fb; --muted:#bdc6d9;
      --card:#111b3f; --btn:#1d2a64; --btn2:#2642a4; --ok:#10b981; --warn:#f59e0b; --err:#ef4444;
      --radius:16px;
    }
    body{margin:0; font-family: ui-sans-serif,system-ui,-apple-system,"Segoe UI",Roboto,Helvetica,Arial,"Apple Color Emoji","Segoe UI Emoji"; background:var(--bg); color:var(--ink);}
    .wrap{max-width:1000px; margin:32px auto; padding:0 16px;}
    .grid{display:grid; grid-template-columns: 1.1fr 1fr; gap:20px}
    .card{background:var(--card); border-radius:var(--radius); padding:18px; box-shadow:0 10px 30px rgba(0,0,0,.25)}
    h1{font-size:clamp(20px,3vw,32px); margin:8px 0 12px}
    .muted{color:var(--muted)}
    button{appearance:none; border:0; border-radius:12px; padding:12px 14px; font-weight:700; color:var(--ink); background:var(--btn); cursor:pointer}
    button[aria-pressed="true"]{background:var(--warn)}
    .row{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
    .mono{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace}
    .bar{height:10px; background:linear-gradient(90deg,#3b82f6,#22d3ee,#10b981,#fbbf24,#ef4444); border-radius:999px}
    .small{font-size:12px}
    .slider{width:100%}
    .legend{display:grid; grid-template-columns:1fr 1fr; gap:6px; margin-top:8px}
    .legend div{display:flex; align-items:center; gap:8px}
    .dot{width:10px; height:10px; border-radius:50%}
    .err{color:var(--err)}
    svg{width:100%; height:auto}
    @media (max-width:900px){ .grid{grid-template-columns: 1fr} }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>声の感情から「花」のイメージを自動生成</h1>
    <p class="muted">録音／音声ファイルを解析 → <span class="mono">{喜び, 怒り, 悲しみ, 中立}</span> の割合に変換 → その分布をパラメータに、<b>SVGの花</b>をプログラム生成します。<br>※ 診断用途ではありません。音声はブラウザ内で処理・保存しません。</p>

    <div class="grid">
      <section class="card" id="left">
        <h2>1) 音声の入力</h2>
        <div class="row">
          <button id="recBtn" aria-pressed="false">● 録音開始</button>
          <input type="file" id="file" accept="audio/*" />
          <span id="status" class="muted small">準備OK</span>
        </div>
        <canvas id="wave" height="90" style="width:100%; margin:12px 0; background:rgba(255,255,255,.05); border-radius:8px"></canvas>

        <h3>2) ざっくり特徴量 → 簡易感情スコア</h3>
        <p class="small muted">WebAudioで <b>音量(RMS)</b>・<b>高さ(ピッチ)</b>・<b>揺れ(ピッチ変動)</b> を推定し、<span class="mono">喜/怒/悲/中</span> の簡易スコアにマッピングします（学習器なしのヒューリスティクス）。
          既存のモデル出力がある場合は下のスライダーで上書き可能。</p>
        <div id="scores"></div>

        <div class="legend">
          <div><span class="dot" style="background:#fbbf24"></span>喜び</div>
          <div><span class="dot" style="background:#ef4444"></span>怒り</div>
          <div><span class="dot" style="background:#60a5fa"></span>悲しみ</div>
          <div><span class="dot" style="background:#9ca3af"></span>中立</div>
        </div>

        <div style="margin-top:10px" class="row">
          <button id="genBtn">🌸 花を生成</button>
          <button id="downloadBtn">⬇︎ SVG保存</button>
        </div>
        <p id="warn" class="err small" hidden></p>
      </section>

      <section class="card" id="right">
        <h2>3) 生成結果</h2>
        <div id="svgHost" style="aspect-ratio:1/1; background:rgba(255,255,255,.03); border-radius:14px; display:grid; place-items:center">
          <div class="muted">ここに花が描かれます</div>
        </div>
        <p class="small muted">可視化ルール：<br>
          ・<b>色相</b>=主成分（喜:黄〜橙／怒:赤／悲:青／中:緑灰）
          ・<b>彩度</b>=覚醒度（音量RMS）／<b>明度</b>=確信度（最大スコア）
          ・<b>花弁数</b>=覚醒度×(5〜24)／<b>尖り</b>=怒り／<b>ドロップ感</b>=悲しみ
        </p>
      </section>
    </div>
  </div>

<script>
(async function(){
  const recBtn = document.getElementById('recBtn');
  const fileInput = document.getElementById('file');
  const statusEl = document.getElementById('status');
  const wave = document.getElementById('wave');
  const wctx = wave.getContext('2d');
  const scoresHost = document.getElementById('scores');
  const svgHost = document.getElementById('svgHost');
  const genBtn = document.getElementById('genBtn');
  const downloadBtn = document.getElementById('downloadBtn');
  const warn = document.getElementById('warn');

  // --- UI helpers ---
  const clamp=(x,a,b)=>Math.max(a,Math.min(b,x));
  const lerp=(a,b,t)=>a+(b-a)*t;
  const softmax = arr => { const m=Math.max(...arr); const ex=arr.map(v=>Math.exp(v-m)); const s=ex.reduce((p,c)=>p+c,0); return ex.map(v=>v/s); };

  // --- Score sliders (to allow manual override or model paste) ---
  const labels = ['喜び','怒り','悲しみ','中立'];
  const colors = ['#fbbf24','#ef4444','#60a5fa','#9ca3af'];
  let weights = [0.25,0.25,0.25,0.25];

  function renderSliders(){
    scoresHost.innerHTML = '';
    labels.forEach((lab,i)=>{
      const wrap=document.createElement('div');
      wrap.style.margin='8px 0';
      wrap.innerHTML = `
        <div class="row small"><b style="min-width:3em">${lab}</b>
          <input class="slider" type="range" min="0" max="1" step="0.01" value="${weights[i]}" data-i="${i}">
          <span class="mono" id="val${i}">${weights[i].toFixed(2)}</span>
          <button class="small" data-rand="${i}" style="background:${colors[i]};opacity:.7">🎲</button>
        </div>
        <div class="bar" style="--v:${weights[i]}"></div>`;
      scoresHost.appendChild(wrap);
    });
    scoresHost.querySelectorAll('input[type=range]').forEach(inp=>{
      inp.addEventListener('input', e=>{
        const i=+e.target.dataset.i; weights[i]=+e.target.value; document.getElementById('val'+i).textContent=weights[i].toFixed(2);
      })
    });
    scoresHost.querySelectorAll('button[data-rand]').forEach(b=>{
      b.addEventListener('click', e=>{
        const i=+e.target.dataset.rand; weights[i]=Math.random(); document.getElementById('val'+i).textContent=weights[i].toFixed(2);
        renderSliders();
      })
    })
  }
  renderSliders();

  // --- Audio pipeline ---
  let mediaStream=null, audioCtx=null, analyser=null, processor=null, source=null;
  let rafId=null;

  function drawWave(){
    if(!analyser) return;
    const N=512; const data=new Float32Array(N);
    analyser.getFloatTimeDomainData(data);
    wctx.clearRect(0,0,wave.width,wave.height);
    wctx.beginPath();
    for(let i=0;i<N;i++){
      const x=i/N*wave.width; const y=(0.5-0.45*data[i])*wave.height; if(i===0) wctx.moveTo(x,y); else wctx.lineTo(x,y);
    }
    wctx.strokeStyle='rgba(255,255,255,.8)'; wctx.lineWidth=2; wctx.stroke();
    rafId=requestAnimationFrame(drawWave);
  }

  async function startRec(){
    mediaStream = await navigator.mediaDevices.getUserMedia({audio:true});
    audioCtx = new (window.AudioContext||window.webkitAudioContext)();
    source = audioCtx.createMediaStreamSource(mediaStream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize=1024;
    processor = audioCtx.createScriptProcessor(2048,1,1);

    let rmsHist=[], pitchHist=[];

    processor.onaudioprocess = e =>{
      const buf=e.inputBuffer.getChannelData(0);
      // RMS
      let sum=0; for(let i=0;i<buf.length;i++){ const v=buf[i]; sum+=v*v }
      const rms=Math.sqrt(sum/buf.length); rmsHist.push(rms);
      // Pitch (autocorrelation, crude)
      const pitch=estimatePitch(buf, audioCtx.sampleRate); if(pitch>0) pitchHist.push(pitch);
      // Every ~0.5s → update scores
      if(rmsHist.length>20){
        const rmsAvg=avg(rmsHist), rmsStd=std(rmsHist); rmsHist=[];
        const pAvg=avg(pitchHist)||0, pStd=std(pitchHist)||0; pitchHist=[];
        const feat={rms:rmsAvg, rmsStd, pitch:pAvg, pitchJitter:pStd};
        weights = heuristicsToEmotion(feat);
        renderSliders();
      }
    }

    source.connect(analyser); analyser.connect(processor); processor.connect(audioCtx.destination);
    drawWave();
  }

  function stopRec(){
    if(rafId) cancelAnimationFrame(rafId);
    if(processor) processor.disconnect(); if(analyser) analyser.disconnect(); if(source) source.disconnect();
    if(mediaStream) mediaStream.getTracks().forEach(t=>t.stop());
    if(audioCtx) audioCtx.close();
    mediaStream=audioCtx=analyser=processor=source=null; rafId=null;
  }

  function avg(a){ return a.length? a.reduce((p,c)=>p+c,0)/a.length : 0 }
  function std(a){ const m=avg(a); return Math.sqrt(a.reduce((p,c)=>p+(c-m)*(c-m),0)/(a.length||1)) }

  function estimatePitch(buf, sr){
    // very crude ACF-based pitch
    const maxLag=Math.round(sr/80), minLag=Math.round(sr/400);
    let bestLag=0, bestCorr=0;
    for(let lag=minLag; lag<=maxLag; lag++){
      let corr=0; for(let i=0;i<buf.length-lag;i++){ corr+=buf[i]*buf[i+lag] }
      if(corr>bestCorr){ bestCorr=corr; bestLag=lag }
    }
    const freq= bestLag? sr/bestLag : 0;
    return (freq>70 && freq<500)? freq : 0;
  }

  function heuristicsToEmotion({rms,rmsStd,pitch,pitchJitter}){
    // Normalize features roughly to [0,1]
    const loud = clamp((rms-0.01)/0.2, 0, 1);           // typical mic
    const stable = 1 - clamp(pitchJitter/40, 0, 1);     // Hz std
    const high = clamp((pitch-150)/200, 0, 1);

    // Map
    // arousal ≈ loud; valence ≈ high*stable - (1-stable)
    const arousal = loud;
    const valence = clamp(high*stable - (1-stable)*0.6, -1, 1);

    let joy = clamp( 0.55*stable + 0.45*high + 0.2*arousal, 0, 1);
    let anger = clamp( 0.6*arousal + 0.25*(1*stable<0.6?1-stable:0) + 0.1*(high<0.3?0.2:0), 0, 1);
    let sad = clamp( 0.7*(1-arousal) + 0.3*(high<0.3?1:0) + 0.2*(1-stable), 0, 1);
    let neutral = clamp( 1 - Math.max(joy, anger, sad), 0, 1);

    const s = softmax([joy, anger, sad, neutral]);
    return s;
  }

  // --- Flower generator (SVG) ---
  function hsl(h,s,l){ return `hsl(${h}, ${Math.round(s*100)}%, ${Math.round(l*100)}%)`; }

  function emotionToPalette([joy, anger, sad, neu]){
    // dominant hue
    let hue = 50*joy + 0*neu + 200*sad + 0*anger; // base contributions
    if(anger>0.35) hue = 0; // push to red when anger noticeable
    if(joy>sad && joy>anger) hue = lerp(48, 28, anger); // joy→yellow/orange when anger mixes
    if(neu>0.6) hue = 120; // greenish neutral

    const arousal = Math.max(joy, anger) * 0.6 + (1 - sad) * 0.2;
    const conf = Math.max(joy, anger, sad, neu);
    const sat = clamp(0.45 + arousal*0.45, 0, 0.95);
    const light = clamp(0.55 + conf*0.25 - anger*0.15, 0.35, 0.9);
    const stem = 120; // green
    return { hue, sat, light, stemHue:stem };
  }

  function drawFlower(weights){
    const [joy, anger, sad, neu] = weights;
    const { hue, sat, light, stemHue } = emotionToPalette(weights);

    // geometry controls
    const arousal = clamp( (joy+anger) - 0.3*sad, 0, 1);
    const petals = Math.round( lerp(6, 24, arousal) );
    const spikiness = clamp( anger*0.9, 0, 0.95 );
    const droop = clamp( sad*0.55, 0, 0.7 );

    const size = 480; const cx=size/2, cy=size/2+40; const r=180;
    let svg = `<svg viewBox="0 0 ${size} ${size}" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="emotion flower">`;
    svg += `<defs>
      <radialGradient id="petalShade" cx="50%" cy="40%">
        <stop offset="0%" stop-color="${hsl(hue,sat,Math.min(1, light+0.1))}"/>
        <stop offset="100%" stop-color="${hsl(hue,Math.max(0,sat-0.15),Math.max(0, light-0.1))}"/>
      </radialGradient>
      <linearGradient id="core" x1="0" y1="0" x2="0" y2="1">
        <stop offset="0%" stop-color="${hsl(hue, sat*0.2, 0.95)}" />
        <stop offset="100%" stop-color="${hsl(hue, sat*0.5, 0.6)}" />
      </linearGradient>
      <linearGradient id="stemGrad" x1="0" y1="0" x2="0" y2="1">
        <stop offset="0%" stop-color="${hsl(stemHue,0.45,0.45)}" />
        <stop offset="100%" stop-color="${hsl(stemHue,0.65,0.25)}" />
      </linearGradient>
    </defs>`;

    // stem
    svg += `<path d="M ${cx} ${cy} C ${cx-20} ${cy+60}, ${cx+20} ${cy+160}, ${cx} ${size-10}" stroke="${hsl(stemHue,0.6,0.35)}" stroke-width="8" fill="none"/>`;

    // leaves
    const leaf = (sx,sy,flip=1)=>{
      const lw=60, lh=36*flip; const rot=flip>0?-25:25;
      return `<g transform="translate(${sx},${sy}) rotate(${rot})">
        <path d="M0 0 C ${lw*0.2} ${-lh}, ${lw*0.8} ${-lh}, ${lw} 0 C ${lw*0.8} ${lh}, ${lw*0.2} ${lh}, 0 0 Z" fill="${hsl(stemHue,0.5,0.35)}" />
      </g>`;
    }
    svg += leaf(cx-30, cy+120, 1) + leaf(cx+30, cy+170, -1);

    // petals
    function petalPath(angle){
      const a = angle * Math.PI/180; // center dir
      const base = 16; // thickness
      const len = r * (1 + spikiness*0.2);
      const droopY = droop * 50;
      // control points for cubic Bezier
      const x1 = cx + Math.cos(a - 0.12)*base;
      const y1 = cy + Math.sin(a - 0.12)*base + droopY;
      const x2 = cx + Math.cos(a) * (len*0.45);
      const y2 = cy + Math.sin(a) * (len*0.45 + droopY);
      const x3 = cx + Math.cos(a) * len;
      const y3 = cy + Math.sin(a) * (len + droopY);
      const x4 = cx + Math.cos(a + 0.12)*base;
      const y4 = cy + Math.sin(a + 0.12)*base + droopY;
      return `M ${x1} ${y1} C ${x2} ${y2}, ${x3} ${y3}, ${x4} ${y4} C ${x3} ${y3}, ${x2} ${y2}, ${x1} ${y1} Z`;
    }

    for(let i=0;i<petals;i++){
      const ang = (360/petals) * i;
      const jitter = (Math.random()-0.5) * spikiness*8; // anger adds randomness
      svg += `<path d="${petalPath(ang+jitter)}" fill="url(#petalShade)" opacity="${lerp(0.6, 0.95, 1 - spikiness*0.5)}"/>`;
    }

    // core
    svg += `<circle cx="${cx}" cy="${cy+ (droop*12)}" r="${lerp(20, 45, Math.max(joy,neu))}" fill="url(#core)" stroke="${hsl(hue, sat*0.6, light*0.8)}" stroke-width="3" />`;

    svg += `</svg>`;
    svgHost.innerHTML = svg;
  }

  // events
  recBtn.addEventListener('click', async ()=>{
    if(recBtn.getAttribute('aria-pressed')==='true'){
      stopRec();
      recBtn.setAttribute('aria-pressed','false'); recBtn.textContent='● 録音開始'; statusEl.textContent='停止しました';
    }else{
      try{
        await startRec();
        recBtn.setAttribute('aria-pressed','true'); recBtn.textContent='■ 録音停止'; statusEl.textContent='録音中… 話してみてください';
      }catch(err){ warn.hidden=false; warn.textContent='マイクが使用できません: '+err; }
    }
  });

  fileInput.addEventListener('change', async (e)=>{
    const file=e.target.files?.[0]; if(!file) return;
    stopRec(); recBtn.setAttribute('aria-pressed','false'); recBtn.textContent='● 録音開始';
    statusEl.textContent='ファイル解析中…';
    const arrayBuf = await file.arrayBuffer();
    const ctx = new (window.AudioContext||window.webkitAudioContext)();
    const audioBuf = await ctx.decodeAudioData(arrayBuf);
    // chunk over buffer to compute features
    const data = audioBuf.getChannelData(0);
    const hop = Math.floor(audioBuf.sampleRate*0.05); // 50ms
    let rmsHist=[], pitchHist=[];
    for(let i=0;i<data.length-hop; i+=hop){
      const seg=data.slice(i,i+hop);
      let sum=0; for(let j=0;j<seg.length;j++){ const v=seg[j]; sum+=v*v }
      rmsHist.push(Math.sqrt(sum/seg.length));
      pitchHist.push( estimatePitch(seg, audioBuf.sampleRate) );
    }
    const feat={rms:avg(rmsHist), rmsStd:std(rmsHist), pitch:avg(pitchHist), pitchJitter:std(pitchHist)};
    weights = heuristicsToEmotion(feat);
    renderSliders(); statusEl.textContent='解析完了';
  });

  genBtn.addEventListener('click', ()=>{
    // normalize weights to sum=1
    const s = softmax(weights);
    drawFlower(s);
  });

  downloadBtn.addEventListener('click', ()=>{
    const svgEl = svgHost.querySelector('svg'); if(!svgEl){ warn.hidden=false; warn.textContent='SVGがまだありません'; return; }
    const blob = new Blob([svgEl.outerHTML], {type:'image/svg+xml'});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a'); a.href=url; a.download='emotion_flower.svg'; a.click();
    setTimeout(()=>URL.revokeObjectURL(url), 500);
  });
})();
</script>
</body>
</html>
